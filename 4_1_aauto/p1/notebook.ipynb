{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb866aca",
   "metadata": {},
   "source": [
    "## 1. Naive-Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe998b",
   "metadata": {},
   "source": [
    "A continuación se realiza la validación de los dos conjuntos de datos utilizando tanto validación cruzada como simple y tanto con corrección de Laplace como sin ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183822c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datos import Datos\n",
    "from Clasificador import ClasificadorNaiveBayes\n",
    "from EstrategiaParticionado import ValidacionCruzada, ValidacionSimple\n",
    "import pandas as pd\n",
    "\n",
    "dataset_german = Datos('data/german.data')\n",
    "dataset_tic = Datos('data/tic-tac-toe.data')\n",
    "\n",
    "cruzada = ValidacionCruzada(5)\n",
    "simple = ValidacionSimple(0.2, 5)\n",
    "seed = 29\n",
    "\n",
    "datasets = [dataset_tic, dataset_german]\n",
    "particionados = [simple, cruzada]\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for p in particionados:\n",
    "    for l in [False, True]:\n",
    "        resultado_parcial = []\n",
    "        for data in datasets:\n",
    "            error, std = ClasificadorNaiveBayes(l).validacion(p, data, seed)\n",
    "            resultado_parcial.append('{:.6f} +/- {:.6f}'.format(error, std))\n",
    "        resultados.append(resultado_parcial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ac708",
   "metadata": {},
   "source": [
    "Una vez realizada la validación, se muestran los datos agrupados en una misma tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af2fd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Error tic-tac-toe.data</th>\n",
       "      <th>Error german.data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validación</th>\n",
       "      <th>Laplace</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Simple</th>\n",
       "      <th>No</th>\n",
       "      <td>0.293194 +/- 0.023647</td>\n",
       "      <td>0.261000 +/- 0.018276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>0.293194 +/- 0.023647</td>\n",
       "      <td>0.264000 +/- 0.015297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Cruzada</th>\n",
       "      <th>No</th>\n",
       "      <td>0.293297 +/- 0.031973</td>\n",
       "      <td>0.248000 +/- 0.019647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>0.291214 +/- 0.030275</td>\n",
       "      <td>0.252000 +/- 0.024413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Error tic-tac-toe.data      Error german.data\n",
       "Validación Laplace                                              \n",
       "Simple     No       0.293194 +/- 0.023647  0.261000 +/- 0.018276\n",
       "           Si       0.293194 +/- 0.023647  0.264000 +/- 0.015297\n",
       "Cruzada    No       0.293297 +/- 0.031973  0.248000 +/- 0.019647\n",
       "           Si       0.291214 +/- 0.030275  0.252000 +/- 0.024413"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(resultados, \n",
    "                  columns=['Error tic-tac-toe.data','Error german.data'], \n",
    "                  index=pd.MultiIndex.from_tuples([('Simple', 'No'), \n",
    "                                                   ('Simple', 'Si'), \n",
    "                                                   ('Cruzada', 'No'), \n",
    "                                                   ('Cruzada', 'Si')], \n",
    "                                                  names=['Validación', 'Laplace']))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e59572",
   "metadata": {},
   "source": [
    "Para ambos conjuntos de datos, el error obtenido es similar. Se obtiene un error ligeramente menor al validar los datos de `german.data`. \n",
    "\n",
    "En cuanto a los distintos tipos de validación (simple o cruzada), al aplicarlos en `tic-tac-toe.data`, la diferencia es apenas notable. Al contrario, en `german.data`, la validación cruzada obtiene un error menor que la validación simple (con una diferencia de aproximadante 2%). \n",
    "\n",
    "La corrección de Laplace tampoco parece que tenga demasiado impacto en la validación de ambos conjuntos de datos (la única situación en la que parece afectar es en `german.data` cuando se utiliza validación cruzada, pero aún así es solo un cambio de aproximadamente un 1%). Esto podría sugerir que para ambos conjuntos de datos, el impacto de la corrección de Laplace es pequeño debido a que no hay ninguna tabla de atributo con una frecuencia de 0.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd3f327",
   "metadata": {},
   "source": [
    "## 2. Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2727422a",
   "metadata": {},
   "source": [
    "Lo primero de todo es separar los datos de los conjuntos de datos en lo que comúnmente se denomina X e y (los valores de los atributos, y los valores de la clase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2e4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "x_tic = dataset_tic.datos.to_numpy()[:, :-1]\n",
    "y_tic = dataset_tic.datos.to_numpy()[:, -1]\n",
    "x_ger = dataset_german.datos.to_numpy()[:, :-1]\n",
    "y_ger = dataset_german.datos.to_numpy()[:, -1]\n",
    "xys = [(x_tic, y_tic), (x_ger, y_ger)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b26822",
   "metadata": {},
   "source": [
    "A continuación realizamos la validación para MultinomialNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3543fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_simple = model_selection.ShuffleSplit(n_splits=5, test_size=0.2)\n",
    "sk_cruzada = model_selection.KFold(n_splits=5, shuffle=True)\n",
    "sk_particiones = [sk_simple, sk_cruzada]\n",
    "\n",
    "resultados_multinomial = []\n",
    "\n",
    "for particion in sk_particiones:\n",
    "    for l in [1.0e-10, 1.0]:\n",
    "        resultado_parcial = []\n",
    "        for x, y in xys:\n",
    "            scores = []\n",
    "            for train_index, test_index in particion.split(x):\n",
    "                # MultinomialNB\n",
    "                model = naive_bayes.MultinomialNB(alpha=l)\n",
    "                model.fit(x[train_index], y[train_index])\n",
    "                \n",
    "                scores.append(model.score(x[test_index], y[test_index]))\n",
    "\n",
    "            resultado_parcial.append('{:.6f} +/- {:.6f}'.format(1 - np.mean(scores), np.std(scores)))\n",
    "        resultados_multinomial.append(resultado_parcial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3692e5a5",
   "metadata": {},
   "source": [
    "Realizamos la validación para GaussianNB (en este caso no tiene sentido aplicar Laplace ya que se modela cada atributo como una distribución normal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a60bc1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_gaussian = []\n",
    "\n",
    "for particion in sk_particiones:\n",
    "    resultado_parcial = []\n",
    "    for x, y in xys:\n",
    "        scores = []\n",
    "        for train_index, test_index in particion.split(x):\n",
    "            model = naive_bayes.GaussianNB()\n",
    "            model.fit(x[train_index], y[train_index])\n",
    "            \n",
    "            scores.append(model.score(x[test_index], y[test_index]))\n",
    "\n",
    "        resultado_parcial.append('{:.6f} +/- {:.6f}'.format(1 - np.mean(scores), np.std(scores)))\n",
    "    resultados_gaussian.append(resultado_parcial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557d803a",
   "metadata": {},
   "source": [
    "Realizamos la validación para CategoricalNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67a5a3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en iteración con german.data. Dato en test no apareció en train, por lo tanto el clasificador no tiene una probabilidad asociada al valor.\n",
      "Error en iteración con german.data. Dato en test no apareció en train, por lo tanto el clasificador no tiene una probabilidad asociada al valor.\n",
      "Error en iteración con german.data. Dato en test no apareció en train, por lo tanto el clasificador no tiene una probabilidad asociada al valor.\n",
      "Error en iteración con german.data. Dato en test no apareció en train, por lo tanto el clasificador no tiene una probabilidad asociada al valor.\n",
      "Error en iteración con german.data. Dato en test no apareció en train, por lo tanto el clasificador no tiene una probabilidad asociada al valor.\n"
     ]
    }
   ],
   "source": [
    "resultados_categorical = []\n",
    "\n",
    "for particion in sk_particiones:\n",
    "    for l in [1.0e-10, 1.0]:\n",
    "        index = -1\n",
    "        resultado_parcial = []\n",
    "        for x, y in xys:\n",
    "            index += 1\n",
    "            scores = []\n",
    "            for train_index, test_index in particion.split(x):\n",
    "                model = naive_bayes.CategoricalNB(alpha=l)\n",
    "                model.fit(x[train_index], y[train_index])\n",
    "                \n",
    "                try:\n",
    "                    scores.append(model.score(x[test_index], y[test_index]))\n",
    "                except IndexError as e:\n",
    "                    print(f'Error en iteración con {[\"tic-tac-toe.data\", \"german.data\"][index]}. Dato en test no apareció en train, por lo tanto el clasificador no tiene una probabilidad asociada al valor.')\n",
    "\n",
    "            resultado_parcial.append('{:.6f} +/- {:.6f}'.format(1 - np.mean(scores), np.std(scores)))\n",
    "        resultados_categorical.append(resultado_parcial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f3a5f3",
   "metadata": {},
   "source": [
    "Por último, aplicamos OneHotEncoder a los conjuntos de datos para comprobar como afecta a MultinomialNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d4ff836",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# Transformación de los datos\n",
    "x_tic_enc = enc.fit_transform(x_tic)\n",
    "x_ger_enc = enc.fit_transform(x_ger)\n",
    "\n",
    "xys_enc = [(x_tic_enc, y_tic), (x_ger_enc, y_ger)]\n",
    "\n",
    "resultados_multinomial_encoded = []\n",
    "\n",
    "for particion in sk_particiones:\n",
    "    for l in [1.0e-10, 1.0]:\n",
    "        resultado_parcial = []\n",
    "        for x, y in xys_enc:\n",
    "            scores = []\n",
    "            for train_index, test_index in particion.split(x):\n",
    "                # MultinomialNB\n",
    "                model = naive_bayes.MultinomialNB(alpha=l)\n",
    "                model.fit(x[train_index], y[train_index])\n",
    "                \n",
    "                scores.append(model.score(x[test_index], y[test_index]))\n",
    "\n",
    "            resultado_parcial.append('{:.6f} +/- {:.6f}'.format(1 - np.mean(scores), np.std(scores)))\n",
    "        resultados_multinomial_encoded.append(resultado_parcial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f7014",
   "metadata": {},
   "source": [
    "A continuación se representan los datos obtenidos en una misma tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfa43c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Error tic-tac-toe.data</th>\n",
       "      <th>Error german.data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clasificador</th>\n",
       "      <th>Validación</th>\n",
       "      <th>Laplace</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Multinomial</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Simple</th>\n",
       "      <th>No</th>\n",
       "      <td>0.353125 +/- 0.011600</td>\n",
       "      <td>0.355000 +/- 0.022804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>0.352083 +/- 0.029573</td>\n",
       "      <td>0.350000 +/- 0.026268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Cruzada</th>\n",
       "      <th>No</th>\n",
       "      <td>0.343396 +/- 0.039223</td>\n",
       "      <td>0.360000 +/- 0.039875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>0.343439 +/- 0.008916</td>\n",
       "      <td>0.360000 +/- 0.043932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Gaussian</th>\n",
       "      <th>Simple</th>\n",
       "      <th>No</th>\n",
       "      <td>0.303125 +/- 0.022438</td>\n",
       "      <td>0.270000 +/- 0.038079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cruzada</th>\n",
       "      <th>No</th>\n",
       "      <td>0.281828 +/- 0.024779</td>\n",
       "      <td>0.266000 +/- 0.029732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Categorical</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Simple</th>\n",
       "      <th>No</th>\n",
       "      <td>0.304167 +/- 0.020989</td>\n",
       "      <td>0.326250 +/- 0.039745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>0.291667 +/- 0.027362</td>\n",
       "      <td>0.267500 +/- 0.042205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Cruzada</th>\n",
       "      <th>No</th>\n",
       "      <td>0.302683 +/- 0.018151</td>\n",
       "      <td>0.308750 +/- 0.016724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>0.294361 +/- 0.020517</td>\n",
       "      <td>0.263333 +/- 0.015456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">MultinomialOneHot</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Simple</th>\n",
       "      <th>No</th>\n",
       "      <td>0.313542 +/- 0.038892</td>\n",
       "      <td>0.300000 +/- 0.046583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>0.290625 +/- 0.036592</td>\n",
       "      <td>0.279000 +/- 0.015620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Cruzada</th>\n",
       "      <th>No</th>\n",
       "      <td>0.296493 +/- 0.030618</td>\n",
       "      <td>0.298000 +/- 0.018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>0.301685 +/- 0.014866</td>\n",
       "      <td>0.269000 +/- 0.031686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Error tic-tac-toe.data  \\\n",
       "Clasificador      Validación Laplace                          \n",
       "Multinomial       Simple     No       0.353125 +/- 0.011600   \n",
       "                             Si       0.352083 +/- 0.029573   \n",
       "                  Cruzada    No       0.343396 +/- 0.039223   \n",
       "                             Si       0.343439 +/- 0.008916   \n",
       "Gaussian          Simple     No       0.303125 +/- 0.022438   \n",
       "                  Cruzada    No       0.281828 +/- 0.024779   \n",
       "Categorical       Simple     No       0.304167 +/- 0.020989   \n",
       "                             Si       0.291667 +/- 0.027362   \n",
       "                  Cruzada    No       0.302683 +/- 0.018151   \n",
       "                             Si       0.294361 +/- 0.020517   \n",
       "MultinomialOneHot Simple     No       0.313542 +/- 0.038892   \n",
       "                             Si       0.290625 +/- 0.036592   \n",
       "                  Cruzada    No       0.296493 +/- 0.030618   \n",
       "                             Si       0.301685 +/- 0.014866   \n",
       "\n",
       "                                          Error german.data  \n",
       "Clasificador      Validación Laplace                         \n",
       "Multinomial       Simple     No       0.355000 +/- 0.022804  \n",
       "                             Si       0.350000 +/- 0.026268  \n",
       "                  Cruzada    No       0.360000 +/- 0.039875  \n",
       "                             Si       0.360000 +/- 0.043932  \n",
       "Gaussian          Simple     No       0.270000 +/- 0.038079  \n",
       "                  Cruzada    No       0.266000 +/- 0.029732  \n",
       "Categorical       Simple     No       0.326250 +/- 0.039745  \n",
       "                             Si       0.267500 +/- 0.042205  \n",
       "                  Cruzada    No       0.308750 +/- 0.016724  \n",
       "                             Si       0.263333 +/- 0.015456  \n",
       "MultinomialOneHot Simple     No       0.300000 +/- 0.046583  \n",
       "                             Si       0.279000 +/- 0.015620  \n",
       "                  Cruzada    No       0.298000 +/- 0.018868  \n",
       "                             Si       0.269000 +/- 0.031686  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_sklearn = []\n",
    "for r in resultados_multinomial, resultados_gaussian, resultados_categorical, resultados_multinomial_encoded:\n",
    "    for x in r:\n",
    "        resultados_sklearn.append(x)\n",
    "\n",
    "df_sklearn = pd.DataFrame(resultados_sklearn, \n",
    "                  columns=['Error tic-tac-toe.data','Error german.data'], \n",
    "                  index=pd.MultiIndex.from_tuples([('Multinomial', 'Simple', 'No'), \n",
    "                                                   ('Multinomial', 'Simple', 'Si'), \n",
    "                                                   ('Multinomial', 'Cruzada', 'No'), \n",
    "                                                   ('Multinomial', 'Cruzada', 'Si'),\n",
    "                                                   ('Gaussian', 'Simple', 'No'),  \n",
    "                                                   ('Gaussian', 'Cruzada', 'No'), \n",
    "                                                   ('Categorical', 'Simple', 'No'), \n",
    "                                                   ('Categorical', 'Simple', 'Si'), \n",
    "                                                   ('Categorical', 'Cruzada', 'No'), \n",
    "                                                   ('Categorical', 'Cruzada', 'Si'),\n",
    "                                                   ('MultinomialOneHot', 'Simple', 'No'), \n",
    "                                                   ('MultinomialOneHot', 'Simple', 'Si'), \n",
    "                                                   ('MultinomialOneHot', 'Cruzada', 'No'), \n",
    "                                                   ('MultinomialOneHot', 'Cruzada', 'Si'),], \n",
    "                                                  names=['Clasificador', 'Validación', 'Laplace']))\n",
    "\n",
    "df_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81257e1d",
   "metadata": {},
   "source": [
    "### `tic-tac-toe.data`\n",
    "\n",
    "En este conjunto de datos todos los clasificadores obtienen mejores resultados que MultinomialNB. CategoricalNB, por ejemplo, obtiene un 5% menos de error, lo cual tiene sentido considerando que todos los atributos del conjunto son categóricos. Aún así, sorprende también observar que GaussianNB obtiene un error muy similar a CategoricalNB (siendo el motivo principal que los atributos categóricos no tienen porque estar modelados correctamente con una distribución normal). De entre todos los clasificadores, el que obtiene los mejores resultados es MultinomialNB una vez se aplica OneHotEncoding a los datos. De nuevo, esto parece lógico ya que todos los atributos del conjunto de datos son categóricos y, por lo tanto, la aplicación de OneHotEncoding resulta muy eficiente.\n",
    "\n",
    "Por lo general, aplicar Laplace obtiene mejores resultados. \n",
    "\n",
    "Por lo general, también, la validación cruzada obtiene mejores resultados que la validación simple.\n",
    "\n",
    "### `german.data`\n",
    "\n",
    "Al igual que en el anterior conjunto de datos, MultinomialNB es el peor clasificador de todos. En este caso, el que obtiene un menor error se trata de GaussianNB (teniendo en cuenta ambas validaciones). Esto podría tener sentido ya que 7 de los 20 atributos en el conjunto de datos son contínuos, por lo tanto su ajuste a través de una normal debería de ser mucho más eficiente que utilizar conteo por ejemplo. Además, como ya hemos visto con el conjunto `tic-tac-toe.data`, aunque haya atributos categóricos/nominales GaussianNB sigue haciendo un buen trabajo con las predicciones (dentro de lo posible). Sorprendentemente, MultinomialNB con OneHotEncoding también funciona bastante bien (quizás porque más de la mitad de los atributos son categóricos y algunos de los númericos no parecen distribuciones continuas sino cuentas o categóricos codificados como enteros). \n",
    "\n",
    "En todos los casos, aplicar Laplace obtiene un menor error.\n",
    "\n",
    "Por lo general, la validación cruzada obtiene menor error que la validación simple. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc15026",
   "metadata": {},
   "source": [
    "## 3. Conclusión\n",
    "\n",
    "En el caso de `tic-tac-toe.data`, nuestra implementación de clasificador Naive Bayes, obtiene un error similar al del mejor clasificador de `scikit-learn` (MultinomialNB con OneHotEncoding). La diferencia es del orden de $0.1\\%$. Para `german.data`, la mejora de nuestro clasificador es un poco más notable, alrededor del $1\\%$. Esto tiene sentido ya que nuestro clasificador tiene una forma \"personalizada\" de tratar cada atributo, diferenciando si son nominales o continuos. En cambio, en este caso, GaussianNB trata a todos de la misma forma (tanto a los nominales como a lso continuos). Era de esperar, por lo tanto, que nuestro clasificador obtuviese un menor error. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d84d7b81462afdff28a7570d02fac67858c4fdbb69eb457c26b33d10893d9ff"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
